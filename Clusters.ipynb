{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1499e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from os.path import join\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "\n",
    "def all_combinations(texts_list, n):\n",
    "    all_combinations = []\n",
    "    texts = combinations(texts_list, n)\n",
    "    for t in texts:\n",
    "        all_combinations.append(list(t))\n",
    "    return(all_combinations)\n",
    "        \n",
    "def intersection(list1,list2):\n",
    "    intersection = list(set(list1) & set(list2))\n",
    "    return intersection\n",
    "\n",
    "def deduplicate_list(l):\n",
    "    l.sort()\n",
    "    return list(l for l,_ in itertools.groupby(l))\n",
    "\n",
    "def remove_subsets(clusters):\n",
    "    return [x for x in clusters if not any(set(x)<=set(y) for y in clusters if x is not y)]\n",
    "\n",
    "def find_text_frequency(text,book_texts):\n",
    "    freq = 0\n",
    "    for book in book_texts:\n",
    "        if text in book_texts[book]:\n",
    "            freq += 1\n",
    "    return freq\n",
    "\n",
    "def find_books_containing_cluster(cluster,book_texts):\n",
    "    books = []\n",
    "    for book in book_texts:\n",
    "        texts = book_texts[book]\n",
    "        if len(intersection(texts,cluster))==len(cluster):\n",
    "            books.append(book)\n",
    "    return books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b633c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'texts_in_books.json'\n",
    "json_file = open(path)\n",
    "json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2390dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_to_exclude = [ 'G151','G152','G153','G153a','G154','G155a','G155b',\n",
    "                    'G155c','G155d','G155e','G156','G156b','G157','G158',\n",
    "                    'G158b' ] \n",
    "\n",
    "## Exclude texts without identification like Calendars\n",
    "\n",
    "## Merge following Heurist IDs\n",
    "\n",
    "merge_hids = {\n",
    "    \n",
    "    544:540,\n",
    "    547:540,\n",
    "    549:540,\n",
    "    550:540,\n",
    "    135517:540,\n",
    "\n",
    "    132476:132477,\n",
    "    135524:132477,\n",
    "    137964:132477,\n",
    "    135511:132477\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1650a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = dict()\n",
    "book_texts = dict()\n",
    "\n",
    "for book in json_data:\n",
    "    \n",
    "    book_id = int(book['id'])\n",
    "\n",
    "\n",
    "    if 'title' in book:\n",
    "        titles[ book_id ] = book['title']\n",
    "    elif 'shelfmark' in book:\n",
    "        titles[ book_id ] = book['shelfmark']\n",
    "    else:\n",
    "        titles[ book_id ] = '[Untitled]'\n",
    "        \n",
    "    texts = book['texts']\n",
    "    \n",
    "    all_texts = []\n",
    "    for text in texts:\n",
    "        \n",
    "        if 'text_id' in text and 'prayer_id' in text:\n",
    "            if text['prayer_id'] not in texts_to_exclude and len(text['prayer_id'].strip()) > 0:\n",
    "                text_id = int(text['text_id'])\n",
    "\n",
    "                \n",
    "                if text_id in merge_hids:\n",
    "                    text_id = merge_hids[text_id]\n",
    "\n",
    "                all_texts.append(text_id)                \n",
    "                if 'title' in text and re.search(r'\\d',str(text_id)):\n",
    "                    titles[text_id] = f\"{text['prayer_id']}: {text['title']}\"\n",
    "            \n",
    "    if len(all_texts)>0:\n",
    "        book_texts[book_id] = all_texts\n",
    "    \n",
    "## Manual assignment of merged titles\n",
    "titles[540] = \"G004: Prayer of St. Gregory to the Arma Christi\"\n",
    "titles[132477] = \"G155_G189c: Long Hours of the Holy Cross with prologue B interwoven with Prayer on Mary's Compassion \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99705f89",
   "metadata": {},
   "source": [
    "## Most frequent texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad220d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G016: Prayer to be recited before the H. Communion (Summe sacerdos et vere pontifex) (168): in 86 books\n",
      "G004: Prayer of St. Gregory to the Arma Christi (540): in 81 books\n",
      "P001: Long Hours of the Holy Spirit (125188): in 66 books\n",
      "G056: Elevation prayer / Prayer to be recited during Mass (127675): in 59 books\n",
      "G048: Prayer to be recited after the H. Communion or after Mass (125687): in 54 books\n",
      "G017: Prayer to be recited after the H. Communion (127529): in 52 books\n",
      "G055: Elevation prayer (127674): in 44 books\n",
      "G007: Prayer to Mary and John the Evangelist (O intemerata) (127681): in 41 books\n",
      "P169: Hundred Articles of the Passion (Noord-Nederlandse bewerking - Hundert Betrachtungen und Begehrungen) (130068): in 40 books\n",
      "G111: Prayer to be recited before (sometimes after) the H. Communion (127464): in 38 books\n"
     ]
    }
   ],
   "source": [
    "text_freq = Counter()\n",
    "\n",
    "for book in book_texts:\n",
    "    texts = book_texts[book]\n",
    "    text_freq.update(texts)\n",
    "    \n",
    "corpus = text_freq.keys()\n",
    "corpus = [text for text in corpus if text_freq[text]>1 ]\n",
    "\n",
    "for text,count in text_freq.most_common(10):\n",
    "    print(f'{titles[text]} ({text}): in {count} books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc3eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289 books\n",
      "507 texts\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(book_texts)} books')\n",
    "print(f'{len(corpus)} texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790c58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cooccurrences(cluster,book_texts):\n",
    "    cooccurrences_freq = Counter()\n",
    "    for book in book_texts:\n",
    "        texts = book_texts[book]\n",
    "        if len(intersection(cluster,texts)) == len(cluster):\n",
    "            cooccurrences = [other_text for other_text in texts if other_text not in cluster]\n",
    "            cooccurrences_freq.update(cooccurrences)\n",
    "    return remove_single_cooccurrences(cooccurrences_freq)\n",
    "\n",
    "def remove_single_cooccurrences(freq):\n",
    "    new_freq = Counter()\n",
    "    for i,count in freq.most_common():\n",
    "        if count>1 and text_freq[i]>1:\n",
    "            new_freq[i]=count\n",
    "    return new_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cca7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## make dataframe; of no use at the moment\n",
    "\n",
    "# rows = []\n",
    "# for book in book_texts:\n",
    "#     row = []\n",
    "#     row.append(book)\n",
    "#     texts = book_texts[book]\n",
    "#     for text in corpus:\n",
    "#         if text in texts:\n",
    "#             row.append(1)\n",
    "#         else:\n",
    "#             row.append(0)\n",
    "#     rows.append(row)\n",
    "    \n",
    "# columns = ['book']\n",
    "# columns.extend(corpus)\n",
    "# #print(columns)\n",
    "# corpus_df = pd.DataFrame(rows,columns=columns)\n",
    "# corpus_df = corpus_df.set_index('book')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541d424",
   "metadata": {},
   "source": [
    "## All clusters of four texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3320fec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 289/289 [00:11<00:00, 25.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19134745\n",
      "17046710\n"
     ]
    }
   ],
   "source": [
    "all_clusters = []\n",
    "\n",
    "## Clusters of four\n",
    "\n",
    "for book in tqdm(book_texts):\n",
    "    texts_list = book_texts[book]\n",
    "    clusters = all_combinations(texts_list, 4)\n",
    "    all_clusters.extend(clusters)\n",
    "    \n",
    "print(len(all_clusters))\n",
    "all_clusters = deduplicate_list(all_clusters)\n",
    "print(len(all_clusters)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c3b99",
   "metadata": {},
   "source": [
    "## Most common clusters of five texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b15e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 507/507 [00:16<00:00, 29.90it/s]\n"
     ]
    }
   ],
   "source": [
    "new_clusters = []\n",
    "\n",
    "for selected_text in tqdm(corpus):\n",
    "#for selected_text in corpus:\n",
    "    #print(selected_text)\n",
    "\n",
    "    cluster = [selected_text]\n",
    "    cooccurrences_counter = find_cooccurrences(cluster,book_texts)\n",
    "    cooccurrences = [text for text,count in cooccurrences_counter.most_common(30)]\n",
    "\n",
    "    clusters = all_combinations(cooccurrences,4)\n",
    "    for new_cluster in clusters:\n",
    "        new_cluster.extend(cluster)\n",
    "        new_clusters.append(new_cluster)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775feb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 4900312/4900312 [31:54<00:00, 2559.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900312 clusters were found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_clusters = deduplicate_list(new_clusters)\n",
    "\n",
    "for new_cluster in tqdm(new_clusters):\n",
    "        \n",
    "    books = find_books_containing_cluster(new_cluster,book_texts)\n",
    "    nr_books = len(books)\n",
    "    ## Clusters need to occur in at least two books\n",
    "    if nr_books >= 2:        \n",
    "        new_cluster = sorted(new_cluster)\n",
    "        all_clusters.append(new_cluster)\n",
    "\n",
    "print(f\"{len(new_clusters)} clusters were found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a2ba4",
   "metadata": {},
   "source": [
    "## Clusters of more than five texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b09ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████▋           | 367/507 [11:11<04:12,  1.81s/it]"
     ]
    }
   ],
   "source": [
    "for selected_text in tqdm(corpus):\n",
    "\n",
    "    cluster = [selected_text]\n",
    "    cooccurrences_counter = find_cooccurrences(cluster,book_texts)\n",
    "    #print(cooccurrences_counter)\n",
    "\n",
    "    for nr_texts in range(1,len(cooccurrences_counter)):\n",
    "        cluster = [selected_text]\n",
    "        for text,count in cooccurrences_counter.most_common(nr_texts):\n",
    "            cluster.append(text)\n",
    "\n",
    "        books = find_books_containing_cluster(cluster,book_texts)\n",
    "        nr_books = len(books)\n",
    "\n",
    "        if nr_books == 0:\n",
    "            break\n",
    "\n",
    "    cluster = sorted(cluster[:-1])\n",
    "    if cluster not in all_clusters:\n",
    "        if len(cluster)>1:\n",
    "            books = find_books_containing_cluster(cluster,book_texts)\n",
    "            if len(books)>1:\n",
    "                all_clusters.append(sorted(cluster))\n",
    "                \n",
    "all_clusters = deduplicate_list(all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4668b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(all_clusters)} clusters were found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i,c in enumerate(all_clusters):\n",
    "    row = []\n",
    "    row.append(i)\n",
    "    row.append(len(c))\n",
    "    books = find_books_containing_cluster(c,book_texts)\n",
    "    row.append(len(books))\n",
    "    rows.append(row)\n",
    "    \n",
    "clusters_df = pd.DataFrame(rows,columns=['id','nr_texts','nr_books'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df.to_csv('clusters.csv')\n",
    "\n",
    "with open('clusters_list.py','w') as out:\n",
    "    out.write(f'all_clusters = {all_clusters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc61e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.read_csv('clusters.csv')\n",
    "clusters_df.query('nr_texts < 15')\n",
    "all_clusters[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b734c1a5",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "\n",
    "    G004\n",
    "    G091\n",
    "    G108\n",
    "    G153a_G189c\n",
    "\n",
    "Ik heb inmiddels twee voorbeelden gevonden waar je hopelijk iets mee kunt. De combinatie van één van de vormen van G004, samen met G091, G108 en G153a_G189c komt voor in 12079, Inv. 291 en Douce 243, maar die cluster van 4 teksten zie ik niet in de lijst. In 12079 en Douce 245 komt G005 bijvoorbeeld ook nog voor.\n",
    "\n",
    "In boeken:\n",
    "\n",
    "    12079 (h_id 125129)\n",
    "    Inv. 291 (h_id 137852 )\n",
    "    Douce 243\n",
    "\n",
    "Een vorm van G155a-e_G189c, samen met een vorm van G004 en bijvoorbeeld G072 en P001 komt voor in Cgm 76 en in BC MS 7, maar die cluster van 4 teksten zie ik ook niet. Het is wat ingewikkeld om de nrs. G155a-e_G189c handmatig te doorzoeken, maar misschien kun je wel achterhalen waarom dergelijke clusters er niet uit komen.\n",
    "\n",
    "    G153a_G189c\n",
    "    G005\n",
    "\n",
    "G153a_G189c nu helemaal is verdwenen in de lijst. Dat is een tekst die niet samengevoegd hoeft te worden met de G155-nummers_G189c, maar staat op zichzelf. G005 komt nu bijvoorbeeld ook helemaal niet voor, terwijl die wel in een cluster zou moeten zitten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6783eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = [127443,127462,134925,540] \n",
    "for text in sorted(cluster):\n",
    "    print(titles[text])\n",
    "    \n",
    "print(sorted(cluster) in all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087044b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = find_books_containing_cluster(cluster,book_texts)\n",
    "\n",
    "for book in books:\n",
    "    print(book)\n",
    "    print(titles[book])\n",
    "    print(sorted(book_texts[book]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dae04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = [127844,125188,540,132477]\n",
    "for text in sorted(cluster):\n",
    "    print(titles[text])\n",
    "    \n",
    "print(sorted(cluster) in all_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694acc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = find_books_containing_cluster(cluster,book_texts)\n",
    "\n",
    "for book in books:\n",
    "    print(titles[book])\n",
    "    print(sorted(book_texts[book]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
